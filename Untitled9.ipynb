{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3iCqrAxxcWIU7kNRuA7P0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanekeshishyan/Armenian-handwritten-letters-classification/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvoG29IfHl0k"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from scipy.signal import convolve2d\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import utils\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelDataset(Dataset):\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"\n",
        "        Initialize the dataset with images and labels data.\n",
        "        \"\"\"\n",
        "        self.file_path = file_path\n",
        "        # image data\n",
        "        self.image_files = []\n",
        "        for root, dirs, files in os.walk(file_path):\n",
        "            for file in files:\n",
        "                if file.endswith(\".png\"):\n",
        "                    self.image_files.append(os.path.join(root, file))\n",
        "\n",
        "        # labels data\n",
        "        self.labels = [int(os.path.basename(os.path.dirname(file))) for file in self.image_files]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = cv2.imread(self.image_files[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        image = torch.from_numpy(image).float().unsqueeze(0)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "fqUX1t7AHtHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "    transforms.RandomRotation(10)\n",
        "])"
      ],
      "metadata": {
        "id": "Ik4WzFNOHv6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = ModelDataset(\"/kaggle/input/mashtots-dataset-v2/Train\")\n",
        "\n",
        "dataset_size = len(full_dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_dataset.dataset.transform = train_transform\n",
        "print(len(train_dataset))\n",
        "batch_size = 32\n",
        "train_loader_augmented = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "for i in range(89, 91):\n",
        "    img, label = train_dataset[i]\n",
        "    print(f\"Image Shape: {img.shape}, Label: {label}\")\n",
        "    plt.imshow(img.squeeze(), cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "for inputs, labels in train_loader_augmented:\n",
        "    print(f\"Batch Shape: {inputs.shape}, Labels: {labels}\")\n",
        "    break\n",
        "\n",
        "for i in range(1):\n",
        "    img, label = train_dataset[i]\n",
        "    transformed_img = train_transform(img)\n",
        "    print(f\"Transformed Image Shape: {transformed_img.shape}, Label: {label}\")\n",
        "    plt.imshow(transformed_img.squeeze(), cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_eUP8R-dHynA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(512, 78)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 128 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "IpRkbwq1H2MY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "model = CNNModel()\n",
        "num_epochs = 25\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "ArB5BAxiH5oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "lr_scheduler_step_size = 10\n",
        "lr_scheduler_gamma = 0.1\n",
        "\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_scheduler_step_size, gamma=lr_scheduler_gamma)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for inputs, labels in train_loader_augmented:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader_augmented)}, Accuracy: {accuracy}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_val_preds = []\n",
        "    all_val_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for val_inputs, val_labels in val_loader:\n",
        "            val_outputs = model(val_inputs)\n",
        "            val_loss += criterion(val_outputs, val_labels).item()\n",
        "\n",
        "            _, val_preds = torch.max(val_outputs, 1)\n",
        "            all_val_preds.extend(val_preds.cpu().numpy())\n",
        "            all_val_labels.extend(val_labels.cpu().numpy())\n",
        "\n",
        "    val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss/len(train_loader_augmented)}, Validation Loss: {val_loss/len(val_loader)}, Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "id": "BWaD1X-WH7-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'armenian_letters_model.pth')\n",
        "\n",
        "test_data=pd.read_csv('/kaggle/input/mashtots-dataset-v2/new_test/new_test.csv')\n",
        "test_tensor = torch.tensor(test_data.values, dtype=torch.float)\n",
        "test_images = test_tensor.reshape((50000, 1, 64, 64))\n",
        "model.load_state_dict(torch.load('armenian_letters_model.pth'))\n",
        "\n",
        "def predict(model, test_batch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data = test_batch\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "    return predicted.cpu().numpy()\n",
        "\n",
        "preds = []\n",
        "for test_batch in torch.split(test_images, 32):\n",
        "  pred = predict(model, test_batch)\n",
        "  preds.extend(pred)\n",
        "\n",
        "submission = pd.DataFrame({'Id': np.arange(1, len(pred) + 1), 'Category': predicted_classes})\n",
        "submission.to_csv('Mysubmission.csv', index=False)"
      ],
      "metadata": {
        "id": "x0WvnMKqH_7C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}